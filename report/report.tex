\title{60-371\\Artificial Intelligence\\Iterated Prisoner's Dilemma}
\author{
		Quinn Perfetto \\
        William Roeder \\
        David Valleau
}
\date{\today}

\documentclass[12pt]{article}

\usepackage{ amssymb }
\usepackage{longtable}
\usepackage[T1]{fontenc}
\usepackage{tocloft}
\usepackage{hyperref}
\usepackage[none]{hyphenat}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue
}
\renewcommand\cftsecleader{\cftdotfill{\cftdotsep}}
\setlength\parindent{0pt}


\begin{document}
\maketitle

\pagebreak
\tableofcontents
\pagebreak

\section{Abstract}

This paper explores the use of multiple Artificial Intelligence algorithms to
create optimal strategies to compete in the Iterated Prisoner's Dilemma.  The
study begins by examining the use of a genetic algorithm to breed the perfect
prisoner.  Several different configurations and fitness functions were tested and
the performance of each was contrasted.  The genetic algorithm was able to
consistently breed well performing prisoners.
A hill climbing approach was then taken,
which proved to be ineffective at producing a competitive strategy given the
lack of a natural successor function. Finally, machine learning... <INSERT
SUMMARY HERE>.  The source code used for this study can be found in the final
section of this paper.

\pagebreak

\section{Introduction}
The Iterated Prisoner's Dilemma is a classic example of game theory which demonstrates
that two agents acting for their own self interest may not result in an
optimal outcome for either agent.  The prisoner's
dilemma is as follows: \\ \\
Two individuals (herein Bob and Alice) have been arrested and placed in solitary
confinement so that they may not communicate with one another.  Each of them hope
to spend the least amount of time in prison.  The prosecutor approaches them
and offers the following deal:
\begin{itemize}
    \item If Bob and Alice betray (herein defect) each other, they will
        both serve 2 years in prison
    \item If Bob defects but Alice remains silent (herein cooperate), Bob
        will be set free and Alice will spend 3 years in prison (and vice versa)
    \item If Bob and Alice both cooperate they will each spend 1 year in prison
        on a lesser charge \\
\end{itemize}

The iterated version of the prisoner's dilemma is simply a sequence of rounds of
the above mentioned game.  A player's score is the summation of their score in
each round. \\

It is implied that Bob and Alice will have no interactions with each other after
their decisions and thus cannot punish/reward their accomplice. If Bob and Alice are
both rational and self centered then they will both choose to defect, as defecting
yields the highest probability of a favourable outcome.  It is interesting to note
that if the prisoners act non-rationally and choose to cooperate
(the "riskier" option) they will spend 1/3 of the time in prison compared
to the rational option. \\

\pagebreak

Taking after J. Golbeck
\footnote{\href{http://cgis.cs.umd.edu/~golbeck/downloads/JGolbeck\_prison.pdf}
{Evolving Strategies for the Prisoner's Dilemma}}
the payoff matrix for this study has been
inverted such that a higher score implies a lesser sentence. \\

\begin{center}
    \begin{tabular}{l | c | c}
         & Cooperate & Defect \\
        \hline
        Cooperate & (3,3) & (5, 0)\\
        \hline
        Defect & (0, 5) & (1,1) \\ \\
    \end{tabular}
\end{center}

Iterated prisoner's dilemma strategies have been widely studied, and many have
concluded that Tit for tat (herein TFT) produces the best average performance.
TFT is extremely simple: Cooperate on the first turn, mirror the opponents
last move thereafter.  TFT is effective because it capitalizes on mutual
cooperation, but is also able to defend itself against rouge defectors.  These
two qualities are extremely important and were kept in mind when designing the
algorithms throughout this paper.
\clearpage
\pagebreak

\section{Genetic Algorithm}

\subsection{Representation}
Each genetic prisoner's strategy is represented as a vector of size
$4^n$ where $n$ is the amount of moves the prisoner keeps in memory.  The
prisoner's move is then calculated by encoding the last $n$ rounds of the game
into an integer and indexing the strategy vector. \\

For example if Bob has
a memory size of one, a possible strategy vector would be
$S_B = [C, C, D, C]$.  If in the previous round Bob cooperated and Alice defected,
the corresponding history string would be represented as $DC$.
The history string is then
marshalled into a base two integer by changing Defections to 0's and Cooperations
to 1's, yielding $01$.  The strategy vector is then indexed at the base
10 representation giving ${S_B}_1 = C$, thus Bob will Cooperate. \\

All examples below use a memory size of three as it was observed to produce the
best results (see observations section \textit{\ref{observations}}).

\subsection{Initial Population}
The initial population was a pool of prisoners having completely randomized
strategy vectors.  The population size was variable, and the effects of varying
sizes are explained in the observations section <OR SHOULD THAT BE HERE?>.

\subsection{Fitness Function}

Three different fitness functions were used to evaluate a prisoners performance.
A description of each as well as performance comparisons follow.

\pagebreak
\subsubsection{Score Against Diverse Opponents}
The prisoner being evaluated would play 100 rounds against a selection of 9
strategies which were thought to be a uniform representation of all possible
strategies.  Total score was calculated and used as a performance grade.
The nine strategies were:
\begin{enumerate}
    \item All C - Always cooperate
    \item All D - Always defect
    \item Tit for Tat - Cooperate first move, mirror opponents last move thereafter
    \item Suspicious Tit for Tat - Defect first move, mirror opponents last move
        thereafter
    \item Tit for 2 Tat - Cooperate first two moves, only cooperate if the
        opponent did not defect twice in a row thereafter
    \item Suspicious Tit for 2 Tat - Defect first two moves, only cooperate if the
        opponent did not defect twice in a row thereafter
    \item Grudger - Cooperate until the opponent defects, then defect without mercy
    \item Sucker - Defect until the opponent cooperates, then cooperate foolishly
    \item Hesitant - Only cooperate if the opponent has cooperated twice in a row
\end{enumerate}

From a shallow point of view this method of evaluating fitness was mostly
successful.  After some contemplation it was decided that the
9 strategies used were slightly biased towards those which tend to cooperate. 
This left some the prisoners produced vulnerable to rouge defectors,
and thus sub-optimal.

\subsubsection{Hamming Distance From TFT Genome}
The prisoner would be evaluated based on the hamming distance
\footnote
{\href{https://en.wikipedia.org/wiki/Hamming_distance}{Hamming distance}}
between its current strategy vector and the strategy vector representing 
the TFT genome.  This obviously had a tendancy to produce prisoners which
acted increasingly similar to TFT.  Although the performance of said bots
was sound, this method did not produce any extraordinary or new strategies.

\subsubsection{Score Against TFT}

The prisoner would be evaluated based on its score after 100 rounds against
TFT.  This method seemed to produce both the best results with the least
amount of computation.

\subsection{Selection}
\subsection{Cross Over}
\subsection{Mutation}



\pagebreak

\section{Hill Climbing}

\pagebreak

\section{Machine Learning}

\pagebreak

\section{Observations}
\label{observations}

\pagebreak

\section{Conclusion}

\pagebreak

\section{Source Code}
All source code for this study was written in C++ and is
available on
\href{https://github.com/Quinny/IteratedPrisoners}{Github}

\end{document}
